{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.10.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About matrix/array multiplication\n\nIn earlier lecture, we discussed about matrix multiplications and mentioned there are two types of multiplications. One of them is the matrix multiplication and other is block multiplication (element-wise)\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nA=np.matrix([[1,2,3],[4,5,6]])\nB=np.matrix([[7,8],[9,10],[11,12]])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Matrix A is:\\n\",A)\nprint(\"Matrix B is:\\n\",B)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The multiplication is calculated as follows:\n\n![step1](images/matrix-multiply-a.svg)\n\n![step2](images/matrix-multiply-b.svg)\n\n![step3 and 4](images/matrix-multiply-c.svg)\n\n[image source](https://www.mathsisfun.com/algebra/matrix-multiplying.html)\n\nHere's Python equivalent for the matrix multiplication. We can use `*` operator or `np.dot()` function.","metadata":{}},{"cell_type":"code","source":"A * B","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.dot(A,B)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# alternative way to write multiplication\nA.dot(B)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The elementwise multiplication (also known as Hadamard product) can be described as:\n\n![Hadamard product](images/4eb9bb54b2820fb3583901ec05bc4b474b6d90bc.png)\n\nAn this can be achieved with `np.multiply()` function","metadata":{}},{"cell_type":"code","source":"C = np.matrix([[1,2],[3,4]])\nD = np.matrix([[5,6],[7,8]])\nprint(\"Matrix C is:\\n\",C)\nprint(\"Matrix D is:\\n\",D)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.multiply(C,D)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Beware that there are some incompatibilities between matrix and 2D array objects, especially for `*` operator. ","metadata":{}},{"cell_type":"code","source":"C_arr = np.array([[1,2],[3,4]])\nD_arr = np.array([[5,6],[7,8]])\nC_arr * D_arr","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `*` operator performs elementwise multiplication in 2D array but performs matrix multiplication for `np.matrix` objects.","metadata":{}},{"cell_type":"code","source":"C * D","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Use of `@` operator for matrix multiplication is safer way for both matrix and array objects","metadata":{}},{"cell_type":"code","source":"C @ D","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"C_arr @ D_arr","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inverse of matrix\n\nYou must be wondering what is the use of inverse of a matrix. Here's an example. Let's assume we want to solve the equations below:\n\n```\nx  +  y +  z  = 6\n     2y + 5z  = −4\n2x + 5y −  z  = 27\n```\n\nThe equations can be written as:\n\n![linear equation to matrix](images/systems-linear-equations-matrices1.svg)\n\nIn that case, if we represent the first matrix as A, we can write:\n\n$$ A\\times X = B$$\n\nand then we can find X as:\n\n$$ X = A^{-1} \\times B$$","metadata":{}},{"cell_type":"markdown","source":"Let's prepare matrices A and B.","metadata":{}},{"cell_type":"code","source":"A = np.matrix([[1,1,1],[0,2,5],[2,5,-1]])\nA","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"B= np.matrix([[6],[-4],[27]])\nB","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, the solution is:","metadata":{}},{"cell_type":"code","source":"A.I * B","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Distance and correlation matrices \n\nWhen data is arranged as matrix or 2D array, then it's easy to calculate distance or correlation between rows and columns. In this example we'll be using a small 2D array in which expression values of 10 genes in 8 samples. In such an arrangement, we might wonder which genes have similar expression pattern. Or, which samples are similar to each other.","metadata":{}},{"cell_type":"code","source":"# this is necessary for fitting matrices to screen\nnp.set_printoptions(threshold=np.inf)\nnp.set_printoptions(linewidth = 150)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport scipy\nfrom scipy import spatial","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here's the sample values. In this example, Gene1 is expressed 5 units in Sample1, 11 units in Sample2 and 1650 units in Sample8.","metadata":{}},{"cell_type":"code","source":"gene_exp = np.array([[5, 11, 18, 9, 1500, 1480, 1530, 1650],\n     [1045, 1225, 1560, 1308, 21, 26, 20, 28],\n     [8375, 9545, 9012, 8798, 17, 18, 17, 18],\n     [2645, 2078, 3815, 3311, 12, 13, 17, 16],\n     [19, 15, 14, 21, 2564, 2486, 2299, 2389],\n     [7346, 8145, 7778, 8214, 19, 16, 14, 12],\n     [1120, 1125, 1298, 1101, 18, 17, 15, 13],\n     [1548, 158, 1493, 1511, 19, 23, 1920, 18],\n     [12, 17, 225, 93, 1545, 1398, 1473, 1579],\n     [5, 3, 2, 5, 156, 1856, 158, 1758]])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gene_exp","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gene_exp.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are various formulas/approaches to calculate distance between two points. In this example, we'll be using *Euclidean* distance. Here's the demonstration in 2D space.\n\n![Euclidean distance](images/euclidean_distance.png)\n\n[Image source](https://towardsdatascience.com/how-to-measure-distances-in-machine-learning-13a396aa34ce)\n\nFor 2D space the formula is:\n\n![Euclidean 2D](images/euclidean_2d.png)\n\nAnd for N dimensional space the formula becomes:\n\n![Euclidean N dimension](images/euclidean_n.png)\n\nLet's calculate pairwise distances between points using `SciPy` module","metadata":{}},{"cell_type":"code","source":"# An example\nscipy.spatial.distance.pdist(gene_exp, 'euclidean')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distances are better visualized in square form. The code below converts pairwise distances in N x N matrix, where each row and column represents a gene.","metadata":{}},{"cell_type":"code","source":"pairwise_dist = scipy.spatial.distance.pdist(gene_exp, 'euclidean')\ndist_matrix = scipy.spatial.distance.squareform(pairwise_dist)\nnp.round(dist_matrix)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Actually, there's better method to reveal patterns. As you can see gene1, gene5, gene9 and gene10 are expressed low in first 4 samples and highly expressed in last 4 samples. Remaining genes show the opposite pattern. Correlation calculations can assign values between 1 and -1 for each pair. If two genes have similar pattern they get higher score and if they have opposite pattern then they get smaller (minus) values. The absolute value increases as similarity increases.\n\nLet's calculate Spearman correlation in our 2D array. Let's view the original data again:","metadata":{}},{"cell_type":"code","source":"gene_exp","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import spearmanr\ngene_correlation = spearmanr(gene_exp, axis=1)[0]\nnp.round(gene_correlation, 2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks like, *Gene1* and *Gene9* has the highest correlation, 0.95 on the other hand *Gene10* and *Gene7* has the highest negative correlation, -0.92\n\nBy changing the axis on which correlation is calculated, we can measure correlation between samples.","metadata":{}},{"cell_type":"code","source":"sample_correlation = spearmanr(gene_exp, axis=0)[0]\nnp.round(sample_correlation, 2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notice the use of `axis=0` or `axis=1` arguments, which allow correlation calculation between samples or genes, respectively.","metadata":{}},{"cell_type":"markdown","source":"# Images as 2D arrays","metadata":{}},{"cell_type":"markdown","source":"Let's see a fun application of numpy and let's see how much it's easy to handle and manipulate images with matplotlib and numpy.\n\nAs you might have guessed images are 2D arrays of pixels. Let's consider the image below, this is extremely zoomed in 4x4 pixel image. ","metadata":{}},{"cell_type":"markdown","source":"![test image zoom](images/test_image_zoom.png)\n\nLet's import this image. Apart from `matplotlib` library, CV (computer vision) library has efficient functions to read images.","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ntest = cv2.imread(\"images/test_image.png\",1)\ntest","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To understand how color is represented in three 8 bit channels please visit [this site](https://www.rapidtables.com/web/color/RGB_Color.html).\n\nWhen printed as list or array, it gives the b,g,r values (instead of R, G, B order as usual) for each pixel.","metadata":{}},{"cell_type":"code","source":"test.tolist()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We also have access the separate channels which is contolled by the third dimension. ","metadata":{}},{"cell_type":"code","source":"test[:,:,0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[:,:,1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[:,:,2]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's try to visualize the arrangement of arrays for each color channel\n\n![color layers](images/color-rgb-array.png)\n\nWhat do you think will happen if we reset (=0) first two layers?","metadata":{}},{"cell_type":"code","source":"only_red=test.copy()\nonly_red[:,:,0:2] = 0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(cv2.cvtColor(only_red, cv2.COLOR_BGR2RGB))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When green and blue channels are reset, only red channel is left. As you expect, now the white pixel is red because when we remove blue and green from white, only red color remains.\n\nLet's remove blue channel this time, which means resetting first layer of 3D array.","metadata":{}},{"cell_type":"code","source":"no_blue=test.copy()\nno_blue[:,:,0] = 0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(cv2.cvtColor(no_blue, cv2.COLOR_BGR2RGB))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When blue is removed from white, red and green left, and mixture of red and green gives yellow color. ","metadata":{}},{"cell_type":"markdown","source":"Let's have some colorful fun starting with an black image. Two arrays are defined, one decreasing from 255 to 0 and other one increasing from 0 255. Both of them are reshaped to 4x4.","metadata":{}},{"cell_type":"code","source":"increasing = np.linspace(0,255,16).reshape(4,4)\ndecreasing = np.linspace(255,0,16).reshape(4,4)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decreasing","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"increasing","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's create an empty vector (filled with zeros actually) and assign `decreasing` array to red channel and `increasing` array to blue channel. Also, remember colors are up to 255, so they should be of type `uint8` (unsigned integer in 8 bits)","metadata":{}},{"cell_type":"code","source":"fun=np.zeros(48, dtype='uint8').reshape(4,4,3)\nfun[:,:,0] = increasing\nfun[:,:,2] = decreasing","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fun","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(cv2.cvtColor(fun, cv2.COLOR_BGR2RGB))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Detection and counting of cells\n\nLet's use a more sophisticated example. Counting cells under microscope is a tiring and tedious process. Can we automate cell counting from images?\n\nThis example will demonstrate cell counting from gray image. You can also check another example, blue-white bacteria colony counting [here](http://www.sixthresearcher.com/counting-blue-and-white-bacteria-colonies-with-python-and-opencv/).","metadata":{}},{"cell_type":"markdown","source":"Let's import sample cell culture image.","metadata":{}},{"cell_type":"code","source":"img = cv2.imread(\"images/0a7d30b252359a10fd298b638b90cb9ada3acced4e0c0e5a3692013f432ee4e9.png\",0)\n\nimg[:10,:10]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img, 'gray')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cell= img[55:80, 140:170]\n#cell","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cell)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(cell, 'gray')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Otsu's thresholding after Gaussian filtering\nblur = cv2.GaussianBlur(cell,(5,5),0)\nprint(blur)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(blur, 'gray')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ret3,th3 = cv2.threshold(blur,0,50,cv2.THRESH_BINARY+cv2.THRESH_OTSU) # cv2.THRESH_BINARY+cv2.THRESH_OTSU neyi hesaplar?\n\n# ret3 == 30\nprint(th3)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nimages = [blur, 0, th3]\ntitles = ['Gaussian filtered Image','Histogram',\"Otsu's Thresholding\"]\nplt.subplot(1,3,1),plt.imshow(images[0],'gray')\nplt.title(titles[0]), plt.xticks([]), plt.yticks([])\nplt.subplot(1,3,2),plt.hist(images[0].ravel(),256)\nplt.title(titles[1]), plt.xticks([]), plt.yticks([])\nplt.subplot(1,3,3),plt.imshow(th3,'gray')\nplt.title(titles[2]), plt.xticks([]), plt.yticks([])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cell.ravel()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, contours = cv2.findContours(th3,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\ncell_contour = cv2.drawContours(cell.copy(), image, -1, (255,255,255), 1) # You must work on copy of cell matrice object because of overwrite problem\nplt.imshow(cell_contour, 'gray')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.subplot(1,2,1),plt.title('Original Image'),plt.imshow(cell, 'gray')#,'red')\nplt.subplot(1,2,2),plt.title('OpenCV.findContours'),plt.imshow(cell_contour,'gray')#,'red')\n\nprint('number of detected contours: ',len(image))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Count cells in whole image","metadata":{}},{"cell_type":"code","source":"img = cv2.imread(\"images/0a7d30b252359a10fd298b638b90cb9ada3acced4e0c0e5a3692013f432ee4e9.png\",0)\nplt.imshow(img, 'gray')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"blur_cells = cv2.GaussianBlur(img,(5,5),0)\n#print(blur)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(blur_cells, 'gray')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ret3_cells,th3_cells = cv2.threshold(blur_cells,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU) # cv2.THRESH_BINARY+cv2.THRESH_OTSU neyi hesaplar?\n\n# ret3_cells == 24\n# print(th3_cells)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nimages = [blur_cells, 0, th3_cells]\ntitles = ['Gaussian filtered Image','Histogram',\"Otsu's Thresholding\"]\nplt.subplot(1,3,1),plt.imshow(images[0],'gray')\nplt.title(titles[0]), plt.xticks([]), plt.yticks([])\nplt.subplot(1,3,2),plt.hist(images[0].ravel(),256)\nplt.title(titles[1]), plt.xticks([]), plt.yticks([])\nplt.subplot(1,3,3),plt.imshow(images[2],'gray')\nplt.title(titles[2]), plt.xticks([]), plt.yticks([])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_cells, contours_cells = cv2.findContours(th3_cells,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\ncells_contour = cv2.drawContours(img.copy(), image_cells, -1, (255,255,255), 2) # width = 2.\nplt.imshow(cells_contour, 'gray')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.subplot(1,2,1),plt.title('Original Image'),plt.imshow(img, 'gray')#,'red')\nplt.subplot(1,2,2),plt.title('OpenCV.findContours'),plt.imshow(cells_contour,'gray')#,'red')\n\nprint('number of detected contours: ',len(image_cells))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Videos are frames of images","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\nvidcap = cv2.VideoCapture('images/cell division animation-ta4mGgoMp1Q.mp4')\n#success,image = vidcap.read()\ncount = 0\ntest=np.zeros(shape=(346,360,640,3)).astype('uint8')\nsuccess = True\nwhile success:\n    #cv2.imwrite(\"frame%d.jpg\" % count, image)     # save frame as JPEG file\n    success,frame = vidcap.read()\n    if not(success): break\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  \n    #print('Read a new frame: ', frame.shape)\n    test[count]=gray\n    count += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test[119].shape)\nplt.imshow(test[119])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(test[119][:,:,0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# problematic frames 39, 105, 114\ntest_frame = np.round(test[105][:,:,0],1)\n# try different gauss blur 5,5 7,7 9,9 and observe specles, 15,15 works best\nblur_frame = cv2.GaussianBlur(test_frame,(15,15),0)\nret3_frame,th3_frame = cv2.threshold(blur_frame,240,255,cv2.THRESH_BINARY)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(th3_frame)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_cells, contours_cells = cv2.findContours(th3_frame,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(image_cells)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_cells_per_frame(frame):\n    blur_frame = cv2.GaussianBlur(frame,(15,15),0)\n    ret3_frame,th3_frame = cv2.threshold(blur_frame,240,255,cv2.THRESH_BINARY)\n    image_cells, contours_cells = cv2.findContours(th3_frame,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n    return len(image_cells)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[ (i,count_cells_per_frame(test[i][:,:,0])) for i in range(345) ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}